{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“GAN.ipynb”",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python37764bita3ae9fea8acf4c558e89c6e00a387a85",
      "display_name": "Python 3.7.7 64-bit"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victorious3/vanila-gan/blob/master/%E2%80%9CGAN%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "5wrV7uqouv46",
        "colab_type": "text"
      },
      "source": [
        "## Setup Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "DAsBlsXouv47",
        "colab_type": "code",
        "outputId": "0e02c8f9-b35e-4607-a44f-982f3f7fee88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy\n",
        "import imageio\n",
        "...\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "5py7tSaQuv5J",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "To simplify, the PyTorch MNIST wrapper, which downloads and loads the MNIST dataset. See the [documentation](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py) for more information about the interface. The default parameters will take 5,000 of the training examples and place them into a validation dataset. The data will be saved into a folder called `MNIST_data`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "tags": [
          "pdf-ignore"
        ],
        "id": "esOAWRXCuv5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " MNIST_data = torchvision.datasets.MNIST(\n",
        "    root='./data/MNIST_data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "MNIST_loader = torch.utils.data.DataLoader(\n",
        "    MNIST_data, batch_size=5000\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwgVNkFsuv5P",
        "colab_type": "text"
      },
      "source": [
        "## Random Noise\n",
        "Generate uniform noise from -1 to 1 with shape `[batch_size, dim]`. Implement `sample_noise` Hint: use `torch.rand`. Make sure noise is the correct shape and type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sample_noise_test",
        "colab_type": "code",
        "outputId": "fa6ee271-b770-4a3a-a6f3-05d18e5de3d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "\n",
        "def sample_noise(batch_size, dim): \n",
        "    return torch.rand([0,1], 5)\n",
        "\n",
        "sample_noise()\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-10e79d3a9fc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msample_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sample_noise() missing 2 required positional arguments: 'batch_size' and 'dim'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExIJoKUtuv5h",
        "colab_type": "text"
      },
      "source": [
        "# Discriminator\n",
        "Our first step is to build a discriminator. Fill in the architecture: A three hidden-layer discriminative neural network.\n",
        " * Fully connected layer \n",
        " * LeakyReLU \n",
        " * Fully connected layer \n",
        " * LeakyReLU \n",
        " * Fully connected layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZFHf7sxuv5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiscriminatorNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()    \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZuso5Ltuv5k",
        "colab_type": "text"
      },
      "source": [
        "# Generator\n",
        "Similar like above:\n",
        " * Fully connected layer\n",
        " * `ReLU`\n",
        " * Fully connected layer\n",
        " * `ReLU`\n",
        " * Fully connected layer\n",
        " * `TanH` (to clip the image to be in the range of [-1,1])\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5SWNf6quv5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneratorNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        in_feat = 128\n",
        "        out_feat = 784\n",
        "\n",
        "        self.Layer0 = nn.Sequential(\n",
        "            nn.Linear(in_feat,256),#do y=Ax+b\n",
        "            nn.LeakyReLU(0,2)#LeakyReLU(x)=max(0,x)+negative_slope∗min(0,x)\n",
        "        )\n",
        "\n",
        "        self.Layer1 = nn.Sequential(\n",
        "            nn.Linear(256,512),\n",
        "            nn.LeakyReLU(0,2)\n",
        "        )\n",
        "\n",
        "        self.Layer2 = nn.Sequential(\n",
        "            nn.Linear(512,1024),\n",
        "            nn.LeakyReLU(0,2)\n",
        "        )\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(1024,out_feat),\n",
        "            nn.Tanh()\n",
        "        )        \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzaT3o-Tuv5v",
        "colab_type": "text"
      },
      "source": [
        "# Optimization\n",
        "Make a function that returns an `optim.Adam` optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6TZIj9y3NtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizers\n",
        "\n",
        "# Loss function\n",
        "loss = nn.BCELoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjAfRT_suv5w",
        "colab_type": "text"
      },
      "source": [
        "# Training a GAN!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "71ZbhmWsuv5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def real_data_target(size):\n",
        "    \n",
        "    return data\n",
        "\n",
        "def fake_data_target(size):\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW40rGb74dBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "    # Reset gradients\n",
        "   \n",
        "    # Train on Real Data\n",
        "    # Calculate error and backpropagate\n",
        "\n",
        "    # Train on Fake Data\n",
        "    # Calculate error and backpropagate \n",
        "    # Update weights with gradients\n",
        "    \n",
        "    # Return error\n",
        "    return \n",
        "def train_generator(optimizer, fake_data):\n",
        "    # Reset gradients\n",
        "    # Sample noise and generate fake data\n",
        "    # Calculate error and backpropagate\n",
        "    # Update weights with gradients\n",
        "    # Return error\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trsS-BrXERnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logger = Logger(model_name='VGAN', data_name='MNIST')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "\n",
        "        # Train Discriminator\n",
        "        # Generate fake data\n",
        "        # Train D\n",
        "\n",
        "\n",
        "        # Train Generator\n",
        "        # Generate fake data\n",
        "        # Train G\n",
        "        # Log error\n",
        "\n",
        "        # Model Checkpoints\n",
        "        logger.save_models(generator, discriminator, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}